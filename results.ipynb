{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chatbot.transformer import Transformer\n",
    "from chatbot.sequential import Sequent\n",
    "from chatbot.rnn import Recurrent\n",
    "import pandas as pd\n",
    "\n",
    "results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConvAI 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/conv-ai-2017'\n",
    "\n",
    "convai_tf = Transformer(num_epoch=100)\n",
    "convai_tf_history = convai_tf.fit(path=path)\n",
    "convai_tf.save_to_folder(path='trained_models/transformer/conv-ai-2017')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convai_seq = Sequent(num_epoch=100)\n",
    "convai_seq_history = convai_seq.fit(path=path)\n",
    "convai_seq.save_to_folder(path='trained_models/dnn/conv-ai-2017')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convai_rnn = Recurrent(num_epoch=100)\n",
    "convai_rnn_history = convai_rnn.fit(path=path)\n",
    "convai_rnn.save_to_folder(path='trained_models/rnn/conv-ai-2017')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cornell Movies Dialogue Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/cornell-movies-dialogue-corpus'\n",
    "\n",
    "cmdc_tf = Transformer(num_epoch=150)\n",
    "cmdc_tf_history = cmdc_tf.fit(path=path)\n",
    "cmdc_tf.save_to_folder(path='trained_models/transformer/cornell-movies-dialogue-corpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmdc_seq = Sequent(num_epoch=150)\n",
    "cmdc_seq_history = cmdc_seq.fit(path=path)\n",
    "cmdc_seq.save_to_folder(path='trained_models/dnn/cornell-movies-dialogue-corpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmdc_rnn = Recurrent(num_epoch=150)\n",
    "cmdc_rnn_history = cmdc_rnn.fit(path=path)\n",
    "cmdc_rnn.save_to_folder(path='trained_models/rnn/cornell-movies-dialogue-corpus')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reddit conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/r-conversations'\n",
    "\n",
    "rc_tf = Transformer(num_epoch=150)\n",
    "rc_tf_history = rc_tf.fit(path=path)\n",
    "rc_tf.save_to_folder(path='trained_models/transformer/r-conversations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc_seq = Sequent(num_epoch=150)\n",
    "rc_seq_history = rc_seq.fit(path=path)\n",
    "rc_seq.save_to_folder(path='trained_models/dnn/r-conversations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc_rnn = Recurrent(num_epoch=150)\n",
    "rc_rnn_history = rc_rnn.fit(path=path)\n",
    "rc_rnn.save_to_folder(path='trained_models/rnn/r-conversations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yandex Toloka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/yandex.toloka'\n",
    "\n",
    "yt_tf = Transformer(lang='ru', num_epoch=200)\n",
    "yt_tf_history = yt_tf.fit(path=path)\n",
    "yt_tf.save_to_folder(path='trained_models/transformer/yandex.toloka')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_seq = Sequent(lang='ru', num_epoch=200)\n",
    "yt_seq_history = yt_seq.fit(path=path)\n",
    "yt_seq.save_to_folder(path='trained_models/dnn/yandex.toloka')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_rnn = Recurrent(lang='ru', num_epoch=200)\n",
    "yt_rnn_history = yt_rnn.fit(path=path)\n",
    "yt_rnn.save_to_folder(path='trained_models/rnn/yandex.toloka')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Summary\n",
    "Printed text models summary after training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConvAI 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convai_tf.summary()\n",
    "convai_seq.summary()\n",
    "convai_rnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cornell Movies Dialogue Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmdc_tf.summary()\n",
    "cmdc_seq.summary()\n",
    "cmdc_rnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reddit conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc_tf.summary()\n",
    "rc_seq.summary()\n",
    "rc_rnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yandex Toloka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_tf.summary()\n",
    "yt_seq.summary()\n",
    "yt_rnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots\n",
    "This sections contains model-to-model comparison plotting by each metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "results = [convai_tf_history, cmdc_tf_history, yt_tf_history, rc_tf_history,\n",
    "            convai_seq_history, cmdc_seq_history, yt_seq_history, rc_seq_history,\n",
    "            convai_rnn_history, cmdc_rnn_history, yt_rnn_history, rc_rnn_history]\n",
    "\n",
    "\n",
    "def plot_metric(data: list[pd.DataFrame], mark:str='accuracy', ep_mark:str='epoch'):\n",
    "    with sns.color_palette('tab10'):\n",
    "        #define grid of plots\n",
    "        fig, axs = plt.subplots(nrows= 3 , ncols= 4 , sharex= True , sharey= True)\n",
    "        fig.set_size_inches((25, 15))\n",
    "        plt.gcf().autofmt_xdate()\n",
    "        #add title\n",
    "        fig.suptitle(f'{mark.title()} comparison plot', size=20)\n",
    "        # axs.set_yticks(np.round(np.linspace(0, 10,5), 2))\n",
    "        \n",
    "        # # s-func\n",
    "        # z = np.zeros(len(data[0][ep_mark]))\n",
    "        # z[::2] = 1\n",
    "        #add data to plots\n",
    "        axs[0, 0].plot(data[0][ep_mark], data[0][mark], color='#6699d3', mfc='#346aa6', marker='o', mec='#b9b9b9', markersize = 4)\n",
    "        axs[0, 0].set(title=f'max:{round(max(data[0][mark].to_list()), 2)}, average:{round(np.mean(data[0][mark].to_list()), 2)}')\n",
    "        axs[0, 0].grid(axis='both')\n",
    "        axs[0, 0].set_ylabel('Transformer model', size='14', color='#346aa6')\n",
    "\n",
    "        axs[0, 1].plot(data[1][ep_mark], data[1][mark], color='#6699d3', mfc='#346aa6', marker='o', mec='#b9b9b9', markersize = 4)\n",
    "        axs[0, 1].set(title=f'max:{round(max(data[1][mark].to_list()), 2)}, average:{round(np.mean(data[1][mark].to_list()), 2)}')\n",
    "        axs[0, 1].grid(axis='both')\n",
    "\n",
    "        axs[0, 2].plot(data[2][ep_mark], data[2][mark], color='#6699d3', mfc='#346aa6', marker='o', mec='#b9b9b9', markersize = 4)\n",
    "        axs[0, 2].set(title=f'max:{round(max(data[2][mark].to_list()), 2)}, average:{round(np.mean(data[2][mark].to_list()), 2)}')\n",
    "        axs[0, 2].grid(axis='both')\n",
    "\n",
    "        axs[0, 3].plot(data[3][ep_mark], data[3][mark], color='#6699d3', mfc='#346aa6', marker='o', mec='#b9b9b9', markersize = 4)\n",
    "        axs[0, 3].set(title=f'max:{round(max(data[3][mark].to_list()), 2)}, average:{round(np.mean(data[3][mark].to_list()), 2)}')\n",
    "        axs[0, 3].grid(axis='both')\n",
    "\n",
    "        axs[1, 0].plot(data[4][ep_mark], data[4][mark], color='#5dd3b0', mfc='#2aa882', marker='o', mec='#b9b9b9', markersize = 4)\n",
    "        axs[1, 0].set(title=f'max:{round(max(data[4][mark].to_list()), 2)}, average:{round(np.mean(data[4][mark].to_list()), 2)}')\n",
    "        axs[1, 0].grid(axis='both')\n",
    "        axs[1, 0].set_ylabel('DNN (Sequential model)', size='14', color='#2aa882')\n",
    "\n",
    "        axs[1, 1].plot(data[5][ep_mark], data[5][mark], color='#5dd3b0', mfc='#2aa882', marker='o', mec='#b9b9b9', markersize = 4)\n",
    "        axs[1, 1].set(title=f'max:{round(max(data[5][mark].to_list()), 2)}, average:{round(np.mean(data[5][mark].to_list()), 2)}')\n",
    "        axs[1, 1].grid(axis='both')\n",
    "\n",
    "        axs[1, 2].plot(data[6][ep_mark], data[6][mark], color='#5dd3b0', mfc='#2aa882', marker='o', mec='#b9b9b9', markersize = 4)\n",
    "        axs[1, 2].set(title=f'max:{round(max(data[6][mark].to_list()), 2)}, average:{round(np.mean(data[6][mark].to_list()), 2)}')\n",
    "        axs[1, 2].grid(axis='both')\n",
    "\n",
    "        axs[1, 3].plot(data[7][ep_mark], data[7][mark], color='#5dd3b0', mfc='#2aa882', marker='o', mec='#b9b9b9', markersize = 4)\n",
    "        axs[1, 3].set(title=f'max:{round(max(data[7][mark].to_list()), 2)}, average:{round(np.mean(data[7][mark].to_list()), 2)}')\n",
    "        axs[1, 3].grid(axis='both')\n",
    "\n",
    "        axs[2, 0].plot(data[8][ep_mark], data[8][mark], color='#ffa270', mfc='#ff8240', marker='o', mec='#b9b9b9', markersize = 4)\n",
    "        axs[2, 0].set(title=f'max:{round(max(data[8][mark].to_list()), 2)}, average:{round(np.mean(data[8][mark].to_list()), 2)}')\n",
    "        axs[2, 0].grid(axis='both')\n",
    "        axs[2, 0].set_xlabel('ConvAI 2017', size='14')\n",
    "        axs[2, 0].set_ylabel('RNN+seq2seq', size='14', color='#ff8240')\n",
    "\n",
    "        axs[2, 1].plot(data[9][ep_mark], data[9][mark], color='#ffa270', mfc='#ff8240', marker='o', mec='#b9b9b9', markersize = 4)\n",
    "        axs[2, 1].set(title=f'max:{round(max(data[9][mark].to_list()), 2)}, average:{round(np.mean(data[9][mark].to_list()), 2)}')\n",
    "        axs[2, 1].grid(axis='both')\n",
    "        axs[2, 1].set_xlabel('Cornell Movied Dialogue Corpus', size='14')\n",
    "\n",
    "        axs[2, 2].plot(data[10][ep_mark], data[10][mark], color='#ffa270', mfc='#ff8240', marker='o', mec='#b9b9b9', markersize = 4)\n",
    "        axs[2, 2].set(title=f'max:{round(max(data[10][mark].to_list()), 2)}, average:{round(np.mean(data[10][mark].to_list()), 2)}')\n",
    "        axs[2, 2].grid(axis='both')\n",
    "        axs[2, 2].set_xlabel('Yandex.Toloka', size='14')\n",
    "\n",
    "        axs[2, 3].plot(data[11][ep_mark], data[11][mark], color='#ffa270', mfc='#ff8240', marker='o', mec='#b9b9b9', markersize = 4)\n",
    "        axs[2, 3].set(title=f'max:{round(max(data[11][mark].to_list()), 2)}, average:{round(np.mean(data[11][mark].to_list()), 2)}')\n",
    "        axs[2, 3].grid(axis='both')\n",
    "        axs[2, 3].set_xlabel('Reddit conversations', size='14')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(results, 'loss', 'epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(results, 'accuracy', 'epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(results, 'mrr', 'epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(results, 'f1', 'epoch')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('tfenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "891e4fc61ac792e208938f292df2fbd7ee5dda42dce8831cfe4bd29bcfe9707e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
